{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Loading...\")\n",
    "\n",
    "data_path ='..\\\\input\\\\'\n",
    "train = pd.read_csv(data_path + 'train.csv', encoding='utf-8', dtype = {'target': np.int32})\n",
    "test = pd.read_csv(data_path + 'test.csv' ,  encoding='utf-8')\n",
    "songs = pd.read_csv(data_path + 'songs.csv', encoding='utf-8')\n",
    "members = pd.read_csv(data_path + 'members.csv', encoding='utf-8', parse_dates = ['expiration_date', 'registration_init_time'])\n",
    "songs_extra = pd.read_csv(data_path + 'song_extra_info.csv', encoding='utf-8')\n",
    "\n",
    "# generate features from isrc, see https://www.dittomusic.com/blog/what-is-an-isrc-code\n",
    "def isrc_to_country(isrc):\n",
    "    if type(isrc) == str:\n",
    "        return isrc[:2]\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "def isrc_to_label(isrc):\n",
    "    if type(isrc) == str:\n",
    "        return isrc[2:5]\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def isrc_to_year(isrc):\n",
    "    if type(isrc) == str:\n",
    "        if int(isrc[5:7]) > 17:\n",
    "            return 1900 + int(isrc[5:7])\n",
    "        else:\n",
    "            return 2000 + int(isrc[5:7])\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "songs_extra['song_year'] = songs_extra['isrc'].apply(isrc_to_year)\n",
    "songs_extra['song_country'] = songs_extra['isrc'].apply(isrc_to_country)\n",
    "songs_extra['record_label'] = songs_extra['isrc'].apply(isrc_to_label)\n",
    "songs_extra.drop(['isrc','name'], axis = 1, inplace =True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Appending...\")\n",
    "df = pd.concat([train, test])\n",
    "df.drop('id', axis=1, inplace=True)\n",
    "\n",
    "print(\"Merging...\")\n",
    "df = pd.merge(df, songs, on = 'song_id', how = 'left')\n",
    "df = pd.merge(df, members, on = \"msno\", how = 'left')\n",
    "df = pd.merge(df, songs_extra, on = \"song_id\", how = 'left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# handing extreme values\n",
    "df.loc[(df['bd']<=0)|(df['bd']>70), 'bd'] = np.nan\n",
    "\n",
    "for col in ['composer','lyricist','artist_name','genre_ids']:\n",
    "    # change all to upper case, remove blanks, replace delimiter with space afterwards \n",
    "    df[col]=df[col].str.upper().str.replace(\" \",\"\")\n",
    "    df[col]=df[col].str.replace(\"|\", \" \").str.replace(\"\\\\\", \" \").str.replace('>',\" \") \\\n",
    "    .str.replace(\"/\", \" \").str.replace('+',' ').str.replace('&',' ').str.replace('„ÄÅ',' ').str.replace('\\\\\\\\',\" \")\n",
    "    # count number of new entity for each col\n",
    "    df[str(col)+\"_nb\"] = df[col].str.count(\" \")+1\n",
    "    df.loc[df[str(col)+\"_nb\"].isnull(), str(col)+\"_nb\"]=0\n",
    "         \n",
    "print('finished counting')\n",
    "\n",
    "# generate new features before label get encoded\n",
    "df['artist_composer'] = 0\n",
    "df.loc[df.artist_name==df.composer, 'artist_composer'] = 1\n",
    "df['composer_lyricist'] = 0\n",
    "df.loc[df.lyricist==df.composer, 'composer_lyricist'] = 1\n",
    "df['three_in_one'] = 0\n",
    "df.loc[(df.artist_name==df.composer)&(df.composer==df.lyricist), 'three_in_one'] = 1\n",
    "\n",
    "add_features=['three_in_one','artist_composer','composer_lyricist',\n",
    "              'composer_nb','lyricist_nb','genre_ids_nb','artist_name_nb']\n",
    "\n",
    "# Memory reduction: \n",
    "for col in add_features:\n",
    "    df[col]=df[col].astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Handle missing... Category to number')\n",
    "\n",
    "enc = LabelEncoder()\n",
    "\n",
    "# for categorical vars saved as string:\n",
    "for col in ['msno', 'song_id', 'source_screen_name', \n",
    "            'source_system_tab', 'source_type', 'genre_ids',\n",
    "            'artist_name', 'composer', 'lyricist',  'gender',\n",
    "            'record_label', 'song_country']:\n",
    "    df[col] = enc.fit_transform(df[col].fillna('nan'))\n",
    "    \n",
    "# for categorical vars saved as int:           \n",
    "for col in ['city', 'language', 'registered_via']:\n",
    "    df[col] = enc.fit_transform(df[col].fillna(-5))\n",
    "\n",
    "# for actual numeric value:\n",
    "df['song_length'].fillna(df['song_length'].median(), inplace = True)\n",
    "df['bd'].fillna(df['bd'].median(), inplace = True)\n",
    "df['song_year'].fillna(method ='ffill', inplace = True) # fill with nearby year\n",
    "\n",
    "# for dates:\n",
    "for col in ['expiration_date', 'registration_init_time']:\n",
    "    df[col] = df[col].apply(lambda x: x.toordinal())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['time'] = df.index / len(df)\n",
    "\n",
    "# Memory reduction: \n",
    "long_col = ['source_screen_name','source_system_tab','source_type',\n",
    "            'bd','language','city','gender','registered_via','song_country' ]\n",
    "for col in long_col:\n",
    "    df[col]=df[col].astype('int8')\n",
    "\n",
    "longer_col = ['record_label','genre_ids','song_year']\n",
    "for col in longer_col:\n",
    "    df[col]=df[col].astype('int16')\n",
    "    \n",
    "train_rows = len(train)\n",
    "\n",
    "train_data = df[:train_rows]\n",
    "test_data = df[train_rows:]\n",
    "\n",
    "print ('save data to local')\n",
    "train_data.to_hdf('../data/train_data.hdf', key='wsdm')\n",
    "test_data.to_hdf('../data/test_data.hdf', key='wsdm')\n",
    "df.to_hdf('../data/df_all.hdf', key='wsdm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('import from local files')\n",
    "\n",
    "train_data = pd.read_hdf('../data/train_data.hdf')\n",
    "test_data = pd.read_hdf('../data/test_data.hdf')\n",
    "#df_all =pd.read_hdf('../data/df_all.hdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "X = train_data.drop(['target'], axis=1)\n",
    "y = train_data.loc[:,'target']\n",
    "X_sub = test_data.drop(['target'], axis=1)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X, y)\n",
    "pred_y_sub = clf.predict_proba(X_sub)\n",
    "subm = pd.DataFrame(pred_y_sub[:,1], columns=['target'])\n",
    "subm['id'] = subm.index\n",
    "subm.to_csv('../output/benchmark.csv.gz', compression='gzip', index=False, float_format='%.5f')\n",
    "\n",
    "print('benchmarking done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "recent = len(test_data) + int(0.05*len(train_data))\n",
    "\n",
    "df_trains = train_data[-recent:]\n",
    "df_history_trains = train_data[:-recent]\n",
    "df_trains.target.to_hdf('../data/ytrain.hdf', key='base')\n",
    "df_all = pd.concat([train_data, test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "add_features=['three_in_one','artist_composer','composer_lyricist',\n",
    "              'composer_nb','lyricist_nb','genre_ids_nb','artist_name_nb',\n",
    "              'song_year','song_country','record_label','id']\n",
    "\n",
    "not_categorical_columns = ['target', 'song_length', 'registration_init_time', 'expiration_date', 'time', 'bd']+add_features\n",
    "\n",
    "categorical_columns = ['artist_name', 'city', 'composer', 'gender', 'genre_ids', 'language',\n",
    "       'lyricist', 'msno', 'registered_via', 'song_id', 'source_screen_name', 'source_system_tab', 'source_type']\n",
    "\n",
    "orders = {}\n",
    "\n",
    "for col in categorical_columns:\n",
    "    orders[col] = 10 ** (int(np.log(df_all[col].max() + 1) / np.log(10)) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_group(df, cols):\n",
    "    \n",
    "    group = df[cols[0]].copy()\n",
    "    for col in cols[1:]:\n",
    "        group = group * orders[col] + df[col] # the combination of n for n in cols\n",
    "        \n",
    "    return group\n",
    "\n",
    "def mean(df_history, df, cols):\n",
    "    \n",
    "    group = get_group(df, cols)\n",
    "    group_history = get_group(df_history, cols)\n",
    "    mean_map = df_history.groupby(group_history).target.mean()\n",
    "    \n",
    "    return group.map(mean_map).fillna(-1)\n",
    "\n",
    "\n",
    "def count(df_history, df, cols):\n",
    "    \n",
    "    group = get_group(df, cols)\n",
    "    group_history = get_group(df_history, cols) \n",
    "    count_map = group_history.value_counts()\n",
    "    \n",
    "    return group.map(count_map).fillna(0)\n",
    "\n",
    "\n",
    "def time_to_next_heard(df_history, df, cols):\n",
    "    \n",
    "    result = []\n",
    "    df_reverse = df.sort_index(ascending=False)\n",
    "    group = get_group(df_reverse,  cols)\n",
    "    \n",
    "    next_heard = {}\n",
    "    for g, t in zip(group, df_reverse.time):\n",
    "        if g in next_heard:\n",
    "            result.append(t - next_heard[g])\n",
    "        else:\n",
    "            result.append(-1)\n",
    "        next_heard[g] = t\n",
    "    \n",
    "    result.reverse()\n",
    "    return result\n",
    "\n",
    "def col_name(cols, func):\n",
    "    return '_'.join(cols) + '_' + func.__name__\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_features(df_history, df):\n",
    "    \n",
    "    X = pd.DataFrame()\n",
    "    \n",
    "    for num_col in [1, 2]:\n",
    "        for cols in combinations(categorical_columns, num_col):\n",
    "            for func in [mean, time_to_next_heard]:\n",
    "                X[col_name(cols, func)] = func(df_history, df, list(cols))\n",
    "                X[col_name(cols, func)] = X[col_name(cols, func)].astype(np.float32)\n",
    "            for func in [count]:\n",
    "                X[col_name(cols, func)] = func(df_history, df, list(cols))\n",
    "                X[col_name(cols, func)] = X[col_name(cols, func)].astype(np.int16)\n",
    "\n",
    "    keep_list= ['song_length', 'bd', 'expiration_date', 'registration_init_time', \n",
    "                'three_in_one','artist_composer','composer_lyricist',\n",
    "                'composer_nb','lyricist_nb','genre_ids_nb','artist_name_nb',\n",
    "                'song_year','song_country','record_label']\n",
    "    \n",
    "    for col in keep_list:\n",
    "        X[col] = df[col]\n",
    "\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xtrain = create_features(df_history_trains, df_trains)\n",
    "Xtrain.to_hdf('../data/Xtrain.hdf', key='base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtest = create_features(train_data, test_data)\n",
    "Xtest.to_hdf('../data/Xtest.hdf', key='base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train with only a sample to find which algorithm and paramters to use.\n",
    "Xtrain = pd.read_hdf('../data/Xtrain.hdf', key='base')[-1500000:-500000]\n",
    "ytrain = pd.read_hdf('../data/ytrain.hdf', key='base')[-1500000:-500000]\n",
    "Xval = pd.read_hdf('../data/Xtrain.hdf', key='base')[-500000:]\n",
    "yval = pd.read_hdf('../data/ytrain.hdf', key='base')[-500000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train LightGBM with default setting\n",
    "d_train = lgb.Dataset(Xtrain, ytrain)\n",
    "val_set = [lgb.Dataset(Xval, yval)]\n",
    "\n",
    "params = {  'objective': 'binary',\n",
    "            'boosting': 'gbdt',\n",
    "            'metric' : 'auc'}\n",
    "\n",
    "print('Start training using default paramters...')\n",
    "default_lgb = lgb.train(params, train_set=d_train, valid_sets=val_set, verbose_eval=20)\n",
    "#[100]\tvalid_0's auc: 0.715786\n",
    "#[100]\tvalid_0's auc: 0.694743"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train LightGBM with adjusted parameters\n",
    "params = {\n",
    "        'objective': 'binary',\n",
    "        'boosting': 'gbdt',\n",
    "        'metric' : 'auc',\n",
    "        'learning_rate': 0.03,\n",
    "        'num_leaves': 2**6,\n",
    "        'bagging_fraction': 0.9,\n",
    "        'bagging_freq': 1,\n",
    "        'bagging_seed': 1,\n",
    "        'feature_fraction': 0.8,\n",
    "        'feature_fraction_seed': 1,\n",
    "        'max_depth': 10\n",
    "    }\n",
    "\n",
    "print('Start training using adjusted paramters...')\n",
    "tuned = lgb.train(params, train_set=d_train, valid_sets=val_set, num_boost_round=500, verbose_eval=20) #0.722774\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yval_preds = tuned.predict(Xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Plot feature importances...')\n",
    "ax = lgb.plot_importance(tuned, max_num_features=15, figsize=(10, 8), importance_type='gain')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compared with other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "tree_para = {\"max_features\":[10, 50],\n",
    "             \"min_samples_leaf\": [10, 100]\n",
    "              }\n",
    "clf = RandomForestClassifier()\n",
    "tree_cv = GridSearchCV(clf, tree_para, cv = tscv, scoring='roc_auc')\n",
    "tree_cv.fit(Xtrain, ytrain)\n",
    "\n",
    "print(\"*********Random Forest Results*********\")\n",
    "print(\"best params are :\", tree_cv.best_params_)\n",
    "print(\"best score is :\", tree_cv.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_tree = tree_cv.predict_proba(Xval)[:,1]\n",
    "np.corrcoef(y_tree, yval_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## AdaBoost Forest (very slow slow)\n",
    "# ada_para = {\"n_estimators\":[200, 300], \n",
    "#             #\"learning_rate\": [0.1, 0.5] \n",
    "#               }\n",
    "\n",
    "# clf = AdaBoostClassifier() #, cv=cv\n",
    "# ada_cv = GridSearchCV(clf, ada_para, cv = tscv, scoring='roc_auc')\n",
    "# ada_cv.fit(Xtrain[-10000:], ytrain[-10000:]) # due to the long training time, set the input data to only last 10,000\n",
    "\n",
    "# print(\"*********AdaBoostClassifier Results*********\")\n",
    "# print(\"best params are :\", ada_cv.best_params_)\n",
    "# print(\"best score is :\", ada_cv.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit using the final train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train with whole dataset\n",
    "Xtrain = pd.read_hdf('../data/Xtrain_original.hdf')\n",
    "ytrain = pd.read_hdf('../data/ytrain.hdf', key='base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_train = lgb.Dataset(Xtrain, ytrain)\n",
    "val_set = [d_train]\n",
    "params = {\n",
    "        'objective': 'binary',\n",
    "        'boosting': 'gbdt',\n",
    "        'learning_rate': 0.03,\n",
    "        'num_leaves': 2**6,\n",
    "        'bagging_fraction': 0.95,\n",
    "        'bagging_freq': 1,\n",
    "        'bagging_seed': 1,\n",
    "        'feature_fraction': 0.9,\n",
    "        'feature_fraction_seed': 1,\n",
    "        'max_depth': 10,\n",
    "        'metric' : 'auc'\n",
    "    }\n",
    "\n",
    "print('Start training...')   \n",
    "model = lgb.train(params, train_set=d_train, num_boost_round=50, valid_sets=val_set, verbose_eval=10)\n",
    "model.save_model('../model_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load model to predict\n",
    "print('Load model')\n",
    "bst = lgb.Booster(model_file='../model_final.csv')\n",
    "print('Plot feature importances...')\n",
    "ax = lgb.plot_importance(bst, importance_type= 'gain', max_num_features=15, figsize=(10, 8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('To predict') \n",
    "Xtest= pd.read_hdf('../data/Xtest_original.hdf')\n",
    "y_pred = bst.predict(Xtest)\n",
    "\n",
    "result_df = pd.DataFrame()\n",
    "result_df['target'] = y_pred\n",
    "result_df['id'] = result_df.index\n",
    "print('Save prediction')                                                 \n",
    "result_df.to_csv('../output/submission.csv.gz', compression = 'gzip', index=False, float_format = '%.5f')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
